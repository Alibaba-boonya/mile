# config file for docserver

# server config session
[server]
# server listen port
port = 18518

# number of threads to use
thread_num = 64

# data roll: master/slave
role = master

# data sync master's listen port
sync_port = 18519

# data sync master addr(IP)
sync_addr = 127.0.0.1

node_id = 1

# docserver working space
work_space = tmp/storage

# log level, values: ERROR WARN INFO DEBUG
log_level = ERROR

# log directory
log_dir = tmp/log

# binlog dir
binlog_dir = tmp/binlog

binlog_maxsize = 209715200

# 标志多长时间内追赶上的门限值，单位：毫秒
binlog_threshold = 1000

# binlog sync interval (msec): 0 for sync imediately, -1 for sync by OS
binlog_sync_interval = 1000

# enable or disable binlog
binlog_flag = 1

# slave pull binlog interval (usec)
slave_pull_interval = 500000

# os overloading threshold (type: double)
load_threshold = 30.0

# storage engine
storage_engine = ldb

# docdb config session
[docdb]

checkpoint_interval = 1800

row_limit = 10000000
max_segment_num = 1000

# disk write thoughout limit (byte/sec)
# 50MB/s
disk_write_limit = 52428800

# always use mmap in all segments
all_mmap = 0

# levledb config
[ldb]

# # table schema define
#
# # table names, seperated by ','
# tables = table1, table2
#
# # row key field
# table1.row_key = field1
# # time key field
# table1.time_key = field2
# # time key length, 4 for int32_t(uint32_t), 8 for int64_t(uint64_t)
# table1.time_key_len = 8
# # time_key * 10^time_key_scale = second
# table1.time_key_scale = -3
#
# # record expire_time (accroding to time_key), second
# # 60 days
# table1.expire_time = 15552000
# 
# # table for pre-computation
# table2.row_key = type
# table2.time_key = time
# table2.time_key_len = 8
# table2.time_key_scale = -3
# table2.expire_time = 15552000
#
# # cumulative index
# table2.cumulative_step = 1000,60000,3600000,86400000
# # aggregate function describe
# table2.aggregate_desc = count(*),max(value),sum(value)
#

# memory table size
write_buffer_size = 33554432
# max open files
max_open_files = 65536
# if true, read data when compacting will verify checksum
paranoid_checks = 1

# block cache size
block_cache_size = 41943040

# sstable size
target_file_size = 8388608
# sstable block size
block_size = 4096
# key is prefix-compressed period in block
block_restart_interval = 16

# Use bloom filter
use_bloom_filter = 0

# Level-0 compaction is started when we hit this many files.
l0_compact_trigger = 4
# Soft limit on number of level-0 files.  We slow down writes at this point.
l0_slowdown_writes_trigger = 8
# Maximum number of level-0 files.  We stop writes at this point.
l0_stop_writes_trigger = 12
# total file size for each level
# level 0 && 1: base_level_size
# level >= 2: base_level_size * 10 * (level - 1)
base_level_size = 20971520
# Maximum level to which a new compacted memtable is pushed if it
# does not create overlap.  We try to push to level 2 to avoid the
# relatively expensive level 0=>1 compactions and to avoid some
# expensive manifest file operations.  We do not push all the way to
# the largest level since that can generate a lot of wasted disk
# space if the same key space is being repeatedly overwritten.
max_mem_compact_level =2

# allowed seeks per target file.
allowed_seeks = 80000

# Use mmap for sstable file access.
allow_mmap_table = 1

# sync to disk for each write, (expensive)
write_sync = 0

# read verify checksums
read_verify_checksums = 0

# vim: syntax=dosini
